{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc4be4f",
   "metadata": {},
   "source": [
    "# MODEL SELECTION MACHINE LEARNING PROJECT- CAR SELLING PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7f784",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95d8a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Car_Name  Year  Selling_Price  Present_Price  Kms_Driven  Owner  \\\n",
      "0     ritz  2014           3.35           5.59       27000      0   \n",
      "1      sx4  2013           4.75           9.54       43000      0   \n",
      "2     ciaz  2017           7.25           9.85        6900      0   \n",
      "3  wagon r  2011           2.85           4.15        5200      0   \n",
      "4    swift  2014           4.60           6.87       42450      0   \n",
      "\n",
      "   Fuel_Type_CNG  Fuel_Type_Diesel  Fuel_Type_Petrol  Seller_Type_Dealer  \\\n",
      "0              0                 0                 1                   1   \n",
      "1              0                 1                 0                   1   \n",
      "2              0                 0                 1                   1   \n",
      "3              0                 0                 1                   1   \n",
      "4              0                 1                 0                   1   \n",
      "\n",
      "   Seller_Type_Individual  Transmission_Automatic  Transmission_Manual  \n",
      "0                       0                       0                    1  \n",
      "1                       0                       0                    1  \n",
      "2                       0                       0                    1  \n",
      "3                       0                       0                    1  \n",
      "4                       0                       0                    1  \n",
      "Orignal Data\n",
      "  Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type  \\\n",
      "0     ritz  2014           3.35           5.59       27000    Petrol   \n",
      "1      sx4  2013           4.75           9.54       43000    Diesel   \n",
      "2     ciaz  2017           7.25           9.85        6900    Petrol   \n",
      "3  wagon r  2011           2.85           4.15        5200    Petrol   \n",
      "4    swift  2014           4.60           6.87       42450    Diesel   \n",
      "\n",
      "  Seller_Type Transmission  Owner  \n",
      "0      Dealer       Manual      0  \n",
      "1      Dealer       Manual      0  \n",
      "2      Dealer       Manual      0  \n",
      "3      Dealer       Manual      0  \n",
      "4      Dealer       Manual      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/ankitsaini-alps/Car-data/main/car%20data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Example: If there are missing values in any column, you can choose to drop or impute them.\n",
    "\n",
    "# Categorical encoding (One-Hot Encoding for categorical variables)\n",
    "data1 = pd.get_dummies(data, columns=['Fuel_Type', 'Seller_Type', 'Transmission'])\n",
    "\n",
    "# Feature Scaling (if necessary)\n",
    "# Example: You can use Min-Max scaling or Standardization.\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(data1.head())\n",
    "\n",
    "print(\"Orignal Data\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c57928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Car_Name       301 non-null    object \n",
      " 1   Year           301 non-null    int64  \n",
      " 2   Selling_Price  301 non-null    float64\n",
      " 3   Present_Price  301 non-null    float64\n",
      " 4   Kms_Driven     301 non-null    int64  \n",
      " 5   Fuel_Type      301 non-null    object \n",
      " 6   Seller_Type    301 non-null    object \n",
      " 7   Transmission   301 non-null    object \n",
      " 8   Owner          301 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 21.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84716023",
   "metadata": {},
   "source": [
    "# Task 2: Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0c1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Selling_Price  Kms_Driven Fuel_Type Seller_Type Transmission  Age\n",
      "0  2014           3.35       27000    Petrol      Dealer       Manual    9\n",
      "1  2013           4.75       43000    Diesel      Dealer       Manual   10\n",
      "2  2017           7.25        6900    Petrol      Dealer       Manual    6\n",
      "3  2011           2.85        5200    Petrol      Dealer       Manual   12\n",
      "4  2014           4.60       42450    Diesel      Dealer       Manual    9\n"
     ]
    }
   ],
   "source": [
    "# Consider domain knowledge or conduct feature analysis to determine relevant features.\n",
    "# For this example, let's assume 'Year', 'Present_Price', 'Kms_Driven', 'Fuel_Type', 'Seller_Type', and 'Transmission' are relevant.\n",
    "\n",
    "selected_features = ['Year', 'Selling_Price', 'Kms_Driven', 'Fuel_Type', 'Seller_Type', 'Transmission']\n",
    "\n",
    "# Create a new DataFrame with selected features\n",
    "data_selected = data[selected_features].copy()\n",
    "\n",
    "# Perform feature engineering (if needed)\n",
    "# Example: Create a new feature 'Age' by subtracting the 'Year' from the current year (2023).\n",
    "current_year = 2023\n",
    "data_selected['Age'] = current_year - data['Year']\n",
    "\n",
    "\n",
    "# Display the updated dataset with selected features and engineered features\n",
    "print(data_selected.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae003a13",
   "metadata": {},
   "source": [
    "# Task 3: Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec6568",
   "metadata": {},
   "source": [
    "# Random Forest Regressor:\n",
    "Suitability: Random Forest is an ensemble learning method that is robust and can handle both numerical and categorical features well. It's suitable for regression tasks like car price prediction due to its ability to capture complex relationships in the data and handle feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1daebf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error: 0.8092164740983593\n",
      "Random Forest R-squared: 0.964871024940323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('car data.csv')\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=['Fuel_Type', 'Seller_Type', 'Transmission'], drop_first=True)\n",
    "\n",
    "# Define the selected features\n",
    "selected_features = ['Selling_Price', 'Year', 'Present_Price', 'Kms_Driven', 'Fuel_Type_Diesel', 'Fuel_Type_Petrol', 'Seller_Type_Individual', 'Transmission_Manual']\n",
    "\n",
    "# Create a new DataFrame with selected features\n",
    "data_selected = data_encoded[selected_features]\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data_selected.drop('Selling_Price', axis=1)\n",
    "y = data_selected['Selling_Price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "r2_rf = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Random Forest Mean Squared Error: {mse_rf}\")\n",
    "print(f\"Random Forest R-squared: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab79d8",
   "metadata": {},
   "source": [
    "# Mean Squared Error (MSE) of approximately 0.809 indicates how close the predicted values are to the actual values. Lower MSE values are better.\n",
    "R-squared (R²) of approximately 0.965 represents the proportion of the variance in the dependent variable (Selling_Price) that is predictable from the independent variables. Higher R² values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e6c8f",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "is another ensemble method that performs well in regression tasks. It builds multiple decision trees sequentially, each correcting the errors of the previous one. It's suitable when you want high predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac65b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Mean Squared Error: 0.7152134580183913\n",
      "Gradient Boosting R-squared: 0.9689517990138945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data_selected.drop('Selling_Price', axis=1)\n",
    "y = data_selected['Selling_Price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gradient Boosting Regressor\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_gb = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"Gradient Boosting Mean Squared Error: {mse_gb}\")\n",
    "print(f\"Gradient Boosting R-squared: {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a92e4",
   "metadata": {},
   "source": [
    "# Linear Regression:\n",
    "\n",
    "Linear Regression is a simple and interpretable algorithm. It's suitable for regression tasks when the relationship between features and the target variable is approximately linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3ce623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error: 3.3602215525053554\n",
      "Linear Regression R-squared: 0.8541290953765206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr_regressor = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lr = lr_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Linear Regression Mean Squared Error: {mse_lr}\")\n",
    "print(f\"Linear Regression R-squared: {r2_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4734934",
   "metadata": {},
   "source": [
    "# Based on these metrics, it appears that the Gradient Boosting model is the best-performing among the three algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527ad25",
   "metadata": {},
   "source": [
    "# Task 4: Training, Evaluation & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d290ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Mean Squared Error: 0.8092164740983593\n",
      "R-squared: 0.964871024940323\n",
      "\n",
      "Gradient Boosting:\n",
      "Mean Squared Error: 0.7152134580183913\n",
      "R-squared: 0.9689517990138945\n",
      "\n",
      "Linear Regression:\n",
      "Mean Squared Error: 3.3602215525053554\n",
      "R-squared: 0.8541290953765206\n",
      "\n",
      "Best Model:\n",
      "GradientBoostingRegressor(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data_selected.drop('Selling_Price', axis=1)\n",
    "y = data_selected['Selling_Price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42)\n",
    "lr_regressor = LinearRegression()\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Mean Squared Error: {mse_rf}\")\n",
    "print(f\"R-squared: {r2_rf}\")\n",
    "print(\"\")\n",
    "\n",
    "# Train the Gradient Boosting model\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "y_pred_gb = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Mean Squared Error: {mse_gb}\")\n",
    "print(f\"R-squared: {r2_gb}\")\n",
    "print(\"\")\n",
    "\n",
    "# Train the Linear Regression model\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "y_pred_lr = lr_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the Linear Regression model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"Mean Squared Error: {mse_lr}\")\n",
    "print(f\"R-squared: {r2_lr}\")\n",
    "print(\"\")\n",
    "\n",
    "# Select the best-performing model based on R-squared\n",
    "best_model = None\n",
    "best_r2 = -1\n",
    "\n",
    "if r2_rf > best_r2:\n",
    "    best_model = rf_regressor\n",
    "    best_r2 = r2_rf\n",
    "\n",
    "if r2_gb > best_r2:\n",
    "    best_model = gb_regressor\n",
    "    best_r2 = r2_gb\n",
    "\n",
    "if r2_lr > best_r2:\n",
    "    best_model = lr_regressor\n",
    "    best_r2 = r2_lr\n",
    "\n",
    "print(\"Best Model:\")\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a9fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
